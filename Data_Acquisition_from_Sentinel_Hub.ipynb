{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC37AKGidxGR"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNDkrM5C5xoU",
        "outputId": "dcf527d6-ac73-4107-d3b9-0ccd6589e7bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentinelhub==3.6.1\n",
            "  Downloading sentinelhub-3.6.1.tar.gz (210 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.8/210.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from sentinelhub==3.6.1) (2.31.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sentinelhub==3.6.1) (8.1.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentinelhub==3.6.1) (1.23.5)\n",
            "Requirement already satisfied: tifffile>=2020.9.30 in /usr/local/lib/python3.10/dist-packages (from sentinelhub==3.6.1) (2023.8.30)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from sentinelhub==3.6.1) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from sentinelhub==3.6.1) (2.8.2)\n",
            "Collecting utm (from sentinelhub==3.6.1)\n",
            "  Downloading utm-0.7.0.tar.gz (8.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from sentinelhub==3.6.1) (2.0.1)\n",
            "Requirement already satisfied: pyproj>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from sentinelhub==3.6.1) (3.6.0)\n",
            "Requirement already satisfied: oauthlib in /usr/local/lib/python3.10/dist-packages (from sentinelhub==3.6.1) (3.2.2)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from sentinelhub==3.6.1) (1.3.1)\n",
            "Collecting aenum>=2.1.4 (from sentinelhub==3.6.1)\n",
            "  Downloading aenum-3.1.15-py3-none-any.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dataclasses-json (from sentinelhub==3.6.1)\n",
            "  Downloading dataclasses_json-0.6.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentinelhub==3.6.1) (4.66.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pyproj>=2.2.0->sentinelhub==3.6.1) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sentinelhub==3.6.1) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sentinelhub==3.6.1) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sentinelhub==3.6.1) (2.0.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->sentinelhub==3.6.1)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json->sentinelhub==3.6.1)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->sentinelhub==3.6.1) (1.16.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->sentinelhub==3.6.1) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json->sentinelhub==3.6.1)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->sentinelhub==3.6.1) (4.5.0)\n",
            "Building wheels for collected packages: sentinelhub, utm\n",
            "  Building wheel for sentinelhub (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentinelhub: filename=sentinelhub-3.6.1-py3-none-any.whl size=231320 sha256=ba3679c9eb1ef3706ad508bf75ad688db276921e5ce2d9ffc60e6033c10386e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/d2/46/5635d21e3660be87a599b26b96e9c1bffb29aec23f8a213188\n",
            "  Building wheel for utm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for utm: filename=utm-0.7.0-py3-none-any.whl size=6085 sha256=c62c060ad17699e45d264c5ee5de63b1e17639c49341c2dbdecf759ce9473e79\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/a1/c8/543df0e8f5e824c3e92a432e32deb9cd89ae686095ee8cfcbe\n",
            "Successfully built sentinelhub utm\n",
            "Installing collected packages: utm, aenum, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, sentinelhub\n",
            "Successfully installed aenum-3.1.15 dataclasses-json-0.6.0 marshmallow-3.20.1 mypy-extensions-1.0.0 sentinelhub-3.6.1 typing-inspect-0.9.0 utm-0.7.0\n",
            "Collecting pykml\n",
            "  Downloading pykml-0.2.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.1/41.1 kB\u001b[0m \u001b[31m565.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.3.6 in /usr/local/lib/python3.10/dist-packages (from pykml) (4.9.3)\n",
            "Installing collected packages: pykml\n",
            "Successfully installed pykml-0.2.0\n",
            "Requirement already satisfied: fiona in /usr/local/lib/python3.10/dist-packages (1.9.4.post1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from fiona) (23.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from fiona) (2023.7.22)\n",
            "Requirement already satisfied: click~=8.0 in /usr/local/lib/python3.10/dist-packages (from fiona) (8.1.7)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.10/dist-packages (from fiona) (1.1.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from fiona) (0.7.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fiona) (1.16.0)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: fiona>=1.8.19 in /usr/local/lib/python3.10/dist-packages (from geopandas) (1.9.4.post1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from geopandas) (23.1)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (1.5.3)\n",
            "Requirement already satisfied: pyproj>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from geopandas) (3.6.0)\n",
            "Requirement already satisfied: shapely>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from geopandas) (2.0.1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (23.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (2023.7.22)\n",
            "Requirement already satisfied: click~=8.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (8.1.7)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (1.1.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (0.7.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->geopandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->geopandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->geopandas) (1.23.5)\n",
            "Collecting geojson\n",
            "  Downloading geojson-3.0.1-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: geojson\n",
            "Successfully installed geojson-3.0.1\n",
            "Collecting rasterio\n",
            "  Downloading rasterio-1.3.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (23.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2023.7.22)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.7)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.23.5)\n",
            "Collecting snuggs>=1.4.1 (from rasterio)\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio) (67.7.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.10/dist-packages (from snuggs>=1.4.1->rasterio) (3.1.1)\n",
            "Installing collected packages: snuggs, affine, rasterio\n",
            "Successfully installed affine-2.4.0 rasterio-1.3.8 snuggs-1.4.7\n"
          ]
        }
      ],
      "source": [
        "!pip install sentinelhub==3.6.1\n",
        "import datetime\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "\n",
        "!pip install pykml\n",
        "!pip install fiona\n",
        "!pip install geopandas\n",
        "\n",
        "from pykml import parser\n",
        "!pip install geojson\n",
        "!pip install rasterio\n",
        "import geojson\n",
        "import geopandas as gpd\n",
        "import fiona\n",
        "\n",
        "from osgeo import gdal\n",
        "import json\n",
        "import re\n",
        "import datetime\n",
        "import os\n",
        "from itertools import product\n",
        "import rasterio as rio\n",
        "from rasterio import windows\n",
        "from tqdm import tqdm\n",
        "\n",
        "fiona.drvsupport.supported_drivers['kml'] = 'rw' # enable KML support which is disabled by default\n",
        "fiona.drvsupport.supported_drivers['KML'] = 'rw' # enable KML support which is disabled by default"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to Drive"
      ],
      "metadata": {
        "id": "A8rmw5lMV8Ue"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwZhlHS5MPm7",
        "outputId": "8e919a98-f5a7-495b-f94c-d093bb140fc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KY4kLlLd2ah"
      },
      "source": [
        "## Sentinel Hub API credentials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xA1uAQm48pO7"
      },
      "outputs": [],
      "source": [
        "from sentinelhub import SentinelHubRequest, DataCollection, MimeType, CRS, BBox, SHConfig, Geometry, MosaickingOrder, SentinelHubDownloadClient, bbox_to_dimensions, bbox_to_resolution, SentinelHubStatistical, SentinelHubStatisticalDownloadClient\n",
        "# Credentials\n",
        "config = SHConfig()\n",
        "config.sh_client_id = '2880617b-83d6-4de8-a837-f7464b698235'\n",
        "config.sh_client_secret = '1S:V#sa3{6I_/vhW.c(/K!A:0,)(2{:i<U<O*J0#'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J39-BUEQ1ZJU"
      },
      "source": [
        "## Specify Time Interval Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2q3uAuK8sLR"
      },
      "outputs": [],
      "source": [
        "def wheat_time_interval(start_year, start_month, start_date, end_year, end_month, end_date, chunks):\n",
        "  start = datetime.datetime(start_year, start_month, start_date)\n",
        "  end = datetime.datetime(end_year, end_month , end_date)\n",
        "  n_chunks = chunks\n",
        "  tdelta = (end - start) / n_chunks\n",
        "  edges = [(start + i * tdelta).date().isoformat() for i in range(n_chunks)]\n",
        "  slots = [(edges[i], edges[i + 1]) for i in range(len(edges) - 1)]\n",
        "\n",
        "  print(\"Monthly time windows:\\n\")\n",
        "  for slot in slots:\n",
        "      print(slot)\n",
        "  return slots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t60OSjyW-g-w"
      },
      "source": [
        "## Specify Evalscript for band acquisition\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The evalscripts are for acquiring: <br>\n",
        "\n",
        "\n",
        "1.   All bands of Sentinel2\n",
        "2.   3 bands (RGB)\n",
        "3.   1 band NDVI\n",
        "4.   1 band DataMask\n",
        "\n",
        "Comment/Uncomment the code as per requirement\n",
        "\n"
      ],
      "metadata": {
        "id": "Q9o_UUNJXHKR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUZtdGQH-Dgx"
      },
      "outputs": [],
      "source": [
        "\n",
        "#*******************ALL BANDS************************************\n",
        "\n",
        "evalscript = \"\"\"\n",
        "\n",
        "//VERSION=3\n",
        "\n",
        "\n",
        "function setup() {\n",
        "  return {\n",
        "    input: [\"B01\",\"B02\",\"B03\",\"B04\",\"B05\",\"B06\",\"B07\",\"B08\",\"B8A\",\"B09\",\"B11\",\"B12\", \"dataMask\"],\n",
        "    output: { bands: 13, sampleType: \"FLOAT32\"}\n",
        "\n",
        "  };\n",
        "}\n",
        "\n",
        "function evaluatePixel(sample) {\n",
        "  return [sample.B01,\n",
        "          sample.B02,\n",
        "          sample.B03,\n",
        "          sample.B04,\n",
        "          sample.B05,\n",
        "          sample.B06,\n",
        "          sample.B07,\n",
        "          sample.B08,\n",
        "          sample.B8A,\n",
        "          sample.B09,\n",
        "          sample.B11,\n",
        "          sample.B12,\n",
        "          sample.dataMask];\n",
        "}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "#*******************ALL BANDS************************************\n",
        "\n",
        "\n",
        "# *******************3 BANDS RGB************************************\n",
        "# evalscript = \"\"\"\n",
        "# //VERSION=3\n",
        "# function setup(){\n",
        "#   return{\n",
        "\n",
        "#      input: [{\n",
        "#       bands: [\"B02\", \"B03\", \"B04\"]\n",
        "#     }],\n",
        "#     output: {bands: 3 }\n",
        "#   }\n",
        "# }\n",
        "\n",
        "# function evaluatePixel(sample){\n",
        "\n",
        "#   return [sample.B04, sample.B03 , sample.B02];\n",
        "# }\n",
        "# \"\"\"\n",
        "#*******************3 BANDS RGB************************************\n",
        "\n",
        "\n",
        "########################  1 BAND NDVI EVALSCRIPT ###############################################\n",
        "# evalscript = \"\"\"\n",
        "\n",
        "# //VERSION=3\n",
        "# function setup() {\n",
        "#   return {\n",
        "#     input: [\"B04\", \"B08\", \"dataMask\"],\n",
        "#     output: { bands: 1, sampleType: \"FLOAT32\" }\n",
        "#   };\n",
        "# }\n",
        "\n",
        "# function evaluatePixel(sample) {\n",
        "#   if (sample.dataMask == 1) {\n",
        "#     let ndvi = index(sample.B08, sample.B04);\n",
        "#     return [ndvi];\n",
        "#   } else {\n",
        "#     return [99]\n",
        "#   }\n",
        "# }\n",
        "\n",
        "# \"\"\"\n",
        "\n",
        "########################  1 BAND NDVI EVALSCRIPT ###############################################\n",
        "\n",
        "\n",
        "# ########################  1 BAND DATA MASK EVALSCRIPT ###############################################\n",
        "\n",
        "# evalscript = \"\"\"\n",
        "\n",
        "# //VERSION=3\n",
        "# function setup() {\n",
        "#   return {\n",
        "#     input: [\"dataMask\"],\n",
        "#     output: { bands: 1, sampleType: \"FLOAT32\" }\n",
        "#   };\n",
        "# }\n",
        "\n",
        "# function evaluatePixel(sample) {\n",
        "#   if (sample.dataMask == 1) {\n",
        "\n",
        "#     return [1];\n",
        "#   } else {\n",
        "#     return [0]\n",
        "#   }\n",
        "# }\n",
        "\n",
        "# \"\"\"\n",
        "########################  1 BAND DATA MASK EVALSCRIPT ###############################################\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## GET TRUE COLOR"
      ],
      "metadata": {
        "id": "3GDePVekYPoT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Satellite data can be downlaoded for a arbitraty polygon using 'Geometry' and for a rectangle boundary box using 'BBox' using code below:"
      ],
      "metadata": {
        "id": "C7wreFKmYVWa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yr2BRGC6Sy4M"
      },
      "source": [
        " ### Geometry"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentinel2 L2A data is acquired in this function using an arbitrary polygon/geometry. The output image returned is of size 48x48 with bicubuc upsampling and mosacking order of least cloud cover.<br>\n",
        "The output size needs to be defined for the resulting file."
      ],
      "metadata": {
        "id": "rUBGGtwAX62V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BWkiITxSyUk"
      },
      "outputs": [],
      "source": [
        "def get_true_color_request(time_interval, file, Geometry1, path):\n",
        "  return SentinelHubRequest(\n",
        "  evalscript=evalscript,\n",
        "  data_folder = os.path.join(path, '%s' %file),\n",
        "  input_data=[\n",
        "      SentinelHubRequest.input_data(\n",
        "          data_collection=DataCollection.SENTINEL2_L2A,\n",
        "          time_interval=time_interval,\n",
        "          other_args={\"dataFilter\": {\"maxCloudCoverage\": 0, \"mosaickingOrder\": \"leastCC\"}, \"processing\": {\"upsampling\": \"BICUBIC\"}}\n",
        "      ),\n",
        "  ],\n",
        "  responses=[\n",
        "      SentinelHubRequest.output_response('default', MimeType.TIFF),\n",
        "  ],\n",
        "  geometry=Geometry1,\n",
        "  size=[48, 48],\n",
        "  config=config\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eS3v7h9bU3cl"
      },
      "source": [
        " ### BBox"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentinel2 L2A data is acquired in this function using a boundary box. The size of the output image is automaticaaly computed based on the passed resoltion of 10m or 60m etc. Bicubuc upsampling and mosacking order of least cloud cover is applied."
      ],
      "metadata": {
        "id": "nfngYMlOYwOK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzjAlMsnUz8l"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_true_color_request_bbox(time_interval, file, bbox_coordinates, path, img_height,\n",
        "                                img_width, resolution):\n",
        "\n",
        "  bbox_size =  bbox_to_dimensions(bbox_coordinates, resolution=resolution)\n",
        "  print(\"Image size is\", bbox_size, \"pixels\")\n",
        "  return SentinelHubRequest(\n",
        "  evalscript=evalscript,\n",
        "  data_folder = os.path.join(path, '%s' %file),\n",
        "  input_data=[\n",
        "      SentinelHubRequest.input_data(\n",
        "          data_collection=DataCollection.SENTINEL2_L2A,\n",
        "          time_interval=time_interval,\n",
        "          other_args={\"dataFilter\": {\"maxCloudCoverage\": 0, \"mosaickingOrder\": \"leastCC\"},\n",
        "                      \"processing\": {\"upsampling\": \"BICUBIC\"}}\n",
        "\n",
        "      ),\n",
        "  ],\n",
        "  responses=[\n",
        "      SentinelHubRequest.output_response('default', MimeType.TIFF),\n",
        "  ],\n",
        "\n",
        "  bbox=bbox_coordinates,\n",
        "  size=bbox_size,\n",
        "  config=config\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PpA4ztp-j3z"
      },
      "source": [
        "##Create Data Request"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmYPM40i-Tcf"
      },
      "outputs": [],
      "source": [
        "# create a list of requests\n",
        "def get_sentinel_data(slots):\n",
        "  list_of_requests = [get_true_color_request(slot) for slot in slots]\n",
        "  # list_of_requests = [request.download_list[0] for request in list_of_requests]\n",
        "\n",
        "  # download data with multiple threads\n",
        "  data = SentinelHubDownloadClient(config=config).download(list_of_requests, max_threads=5)\n",
        "  return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88yc5YKj-wuv"
      },
      "source": [
        "##PRINT DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXl8ufZE-vQZ"
      },
      "outputs": [],
      "source": [
        "# some stuff for pretty plots\n",
        "def print_time_series(passed_data):\n",
        "  ncols = 15\n",
        "  nrows = 13\n",
        "  aspect_ratio = 1\n",
        "  subplot_kw = {\"xticks\": [], \"yticks\": [], \"frame_on\": False}\n",
        "\n",
        "  fig, axs = plt.subplots(ncols=ncols, nrows=nrows, figsize=(5 * ncols * aspect_ratio, 5 * nrows), subplot_kw=subplot_kw)\n",
        "\n",
        "  for idx, image in enumerate(passed_data):\n",
        "      ax = axs[idx // ncols][idx % ncols]\n",
        "      ax.imshow(np.clip(image * 2.5 / 255, 0, 1))\n",
        "      ax.set_title(f\"{slots[idx][0]}  -  {slots[idx][1]}\", fontsize=10)\n",
        "  plt.tight_layout()\n",
        "  # plt.savefig('%s %d %s' %(\"Wheat\", year, \"Original\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7iQyCtpIIpg"
      },
      "source": [
        "#Request data for BBox"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbrF5S73IT01"
      },
      "source": [
        "##Convert to BBox with 2 corners only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gD9ePBsKPPIV"
      },
      "outputs": [],
      "source": [
        "#function to get the 2 corners of a rectangle/square because BBox requires 2 corner coordinates only (top-left and bottom-right)\n",
        "def bbox(coord_list):\n",
        "     box = []\n",
        "     for i in (0,1):\n",
        "         res = sorted(coord_list, key=lambda x:x[i])\n",
        "         box.append((res[0][i],res[-1][i]))\n",
        "     box_list = [box[0][0], box[1][0], box[0][1], box[1][1]]\n",
        "    #  ret = f\"{box[0][0]}, {box[1][0]}, {box[0][1]}, {box[1][1]}\"\n",
        "     return box_list\n",
        "\n",
        "#https://gis.stackexchange.com/questions/313011/convert-geojson-object-to-bounding-box-using-python-3-6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fk0xJ8weK1KO",
        "outputId": "b614ec1b-838e-41a5-9b07-c937432cc1ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Name Description  \\\n",
            "0  Untitled Polygon               \n",
            "\n",
            "                                            geometry  \n",
            "0  POLYGON Z ((74.08510 32.04691 0.00000, 74.1102...  \n",
            "[[[[74.08509621709523, 32.04690553751833, 0.0], [74.11029447946628, 32.0469351520649, 0.0], [74.11036035817298, 32.06877269941585, 0.0], [74.08504604567621, 32.06880147017053, 0.0], [74.08509621709523, 32.04690553751833, 0.0]]]]\n",
            "[74.085046, 32.046906, 74.11036, 32.068801]\n",
            "Monthly time windows:\n",
            "\n",
            "('2021-11-01', '2021-11-29')\n",
            "('2021-11-29', '2021-12-27')\n",
            "('2021-12-27', '2022-01-24')\n",
            "('2022-01-24', '2022-02-21')\n",
            "('2022-02-21', '2022-03-21')\n",
            "('2022-03-21', '2022-04-18')\n",
            "['2021-11-29', '2021-12-27', '2022-01-24', '2022-02-21', '2022-03-21', '2022-04-18']\n",
            "Image size is (241, 241) pixels\n",
            "Image size is (241, 241) pixels\n",
            "Image size is (241, 241) pixels\n",
            "Image size is (241, 241) pixels\n",
            "Image size is (241, 241) pixels\n",
            "Image size is (241, 241) pixels\n"
          ]
        }
      ],
      "source": [
        "# Create a new dataframe for storing the polygons\n",
        "ground_truth = gpd.GeoDataFrame()\n",
        "driver = 'KML'\n",
        "\n",
        "#path to your .kml file\n",
        "polygon_file_path = \"/content/Untitled Polygon.kml\"\n",
        "#extract filename from directory\n",
        "directory, file = os.path.split(polygon_file_path)\n",
        "\n",
        "# polpulate the dataframe using the .kml file containing all polygons\n",
        "for layer in fiona.listlayers(polygon_file_path):\n",
        "  s = gpd.read_file(polygon_file_path, driver=driver, layer=layer)\n",
        "  ground_truth = pd.concat([ground_truth, s], ignore_index=True)\n",
        "  print(ground_truth)\n",
        "\n",
        "##extract geometrical coordinates of all the polygons in the .kml file\n",
        "multi_polygon_coordinates=[]\n",
        "for geo_shape in ground_truth.geometry.values:\n",
        "  temp_polygon = list(map(list, (geo_shape.exterior.coords)))\n",
        "  # print(\"temp_polygon\", temp_polygon)\n",
        "  multi_polygon_coordinates.append(list([temp_polygon]))\n",
        "print(multi_polygon_coordinates)\n",
        "\n",
        "# parse your json here\n",
        "poly=geojson.Polygon(multi_polygon_coordinates)\n",
        "bbox_coordinates = bbox(list(geojson.utils.coords(poly))) #function call to get 2 corner coordinates of BBox\n",
        "print(bbox_coordinates)\n",
        "\n",
        "#specify resolution and coordinates in CRS\n",
        "resolution = 10 #in meters\n",
        "img_height = img_width=128\n",
        "bbox_coordinates = BBox(bbox=bbox_coordinates, crs=CRS.WGS84)\n",
        "\n",
        "##specify time slots\n",
        "slots = wheat_time_interval(2021, 11, 1, 2022, 5, 17, 7) #start_year, start_month, start_date, end_year, end_month, end_date, chunks\n",
        "results = [slot[1] for slot in slots]\n",
        "print(results)\n",
        "\n",
        "#specify path for saving data in drive\n",
        "path = '/content/4/'\n",
        "##get and save data\n",
        "for slot in slots:\n",
        "  data = get_true_color_request_bbox(slot, file, bbox_coordinates, path, img_height, img_width, resolution)\n",
        "  data.save_data()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knIHv8NMU5fC"
      },
      "source": [
        "##BBox to dimensions\n",
        "*SPECIFY* resolution of 1 pixel and *GET* image size accordingly (in pixels)\n",
        "E.g. Specifying 10m resolution gives (137, 79) pixels image size for whatever area (on ground in km2 etc.) you input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWDbyiOPCuhe",
        "outputId": "d4946fb6-fc6b-470c-99e0-765d0aac0639"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image shape at 20 m resolution: (68, 39) pixels\n"
          ]
        }
      ],
      "source": [
        "resolution=20\n",
        "betsiboka_size = bbox_to_dimensions(bbox_coordinates, resolution=resolution)\n",
        "\n",
        "print(f\"Image shape at {resolution} m resolution: {betsiboka_size} pixels\")\n",
        "\n",
        "# https://sentinelhub-py.readthedocs.io/en/latest/examples/process_request.html\n",
        "\n",
        "# bbox_to_dimensions\n",
        "# \"\"\"Calculates width and height in pixels for a given bbox of a given pixel resolution (in meters). The result is\n",
        "#     rounded to the nearest integers.\n",
        "\n",
        "#     :param bbox: bounding box\n",
        "#     :param resolution: Resolution of desired image in meters. It can be a single number or a tuple of two numbers -\n",
        "#         resolution in horizontal and resolution in vertical direction.\n",
        "#     :return: width and height in pixels for given bounding box and pixel resolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2EqnSzPUxy6"
      },
      "source": [
        "##BBox to resolution\n",
        "specify image size (in pixels) and get resolution of image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pL-J1a1_UM_D",
        "outputId": "8ff722d1-a3a9-4239-cf5a-be8d6b02f54c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image shape at 10 m resolution: (9.977830713376042, 9.97329445701399) pixels\n"
          ]
        }
      ],
      "source": [
        "betsiboka_size = bbox_to_resolution(bbox_coordinates, 137 ,79 ,True)\n",
        "\n",
        "print(f\"Image shape at {resolution} m resolution: {betsiboka_size} pixels\")\n",
        "\n",
        "#  \"\"\"Calculates pixel resolution for a given bbox of a given width and height. By default, it returns result in\n",
        "#     meters.\n",
        "\n",
        "#     :param bbox: bounding box\n",
        "#     :param width: width of bounding box in pixels\n",
        "#     :param height: height of bounding box in pixels\n",
        "#     :param meters: If `True` result will be given in meters, otherwise it will be given in units of current CRS\n",
        "#     :return: resolution east-west at north and south, and resolution north-south for given CRS\n",
        "#     :raises: ValueError if CRS is not supported"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YFP1wWB1ITc"
      },
      "source": [
        "#Request data for Single Polygon using .kmz file"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code is for extracting"
      ],
      "metadata": {
        "id": "pKc6l5KaZ3Bk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzBHbs9B_lw1"
      },
      "outputs": [],
      "source": [
        "def convert_rec(x):\n",
        "    if isinstance(x, list):\n",
        "        return list(map(convert_rec, x))\n",
        "    else:\n",
        "        return float(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cerb022KfahI",
        "outputId": "dfdb1fd6-dd1f-4b16-9326-178ed9aa8b65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Monthly time windows:\n",
            "\n",
            "('2021-11-01', '2021-11-20')\n",
            "('2021-11-20', '2021-12-10')\n",
            "('2021-12-10', '2021-12-29')\n",
            "('2021-12-29', '2022-01-18')\n",
            "('2022-01-18', '2022-02-06')\n",
            "('2022-02-06', '2022-02-26')\n",
            "('2022-02-26', '2022-03-17')\n",
            "('2022-03-17', '2022-04-06')\n",
            "('2022-04-06', '2022-04-25')\n",
            "['2021-11-20', '2021-12-10', '2021-12-29', '2022-01-18', '2022-02-06', '2022-02-26', '2022-03-17', '2022-04-06', '2022-04-25']\n"
          ]
        }
      ],
      "source": [
        "dir = '/content/6/'\n",
        "print_once=True #print only a single loop\n",
        "i=0\n",
        "df=pd.DataFrame\n",
        "count=0\n",
        "for file in sorted(os.listdir(dir)):\n",
        "\n",
        "  final_coordinates=[]\n",
        "\n",
        "  if file.endswith(\".kmz\"):\n",
        "    dir2 = os.path.join(dir,file)\n",
        "    #print(\"Shwoing one directory path\", dir2)\n",
        "\n",
        "    ##unzipping each KMZ file leads to a doc.kml file\n",
        "    kmz = ZipFile(dir2, 'r')\n",
        "    kml = kmz.open('doc.kml', 'r').read()\n",
        "\n",
        "    ##extract coordinated from each kml file\n",
        "    root = parser.fromstring(kml)\n",
        "    extracted_coordinates=root.Document.Placemark.Polygon.outerBoundaryIs.LinearRing.coordinates\n",
        "    # print(extracted_coordinates)\n",
        "    #print(\"Extracted Coordinates\", dir2, extracted_coordinates)\n",
        "\n",
        "    ##retrieve the coordinates as text from lxml.objectify.StringElement\n",
        "    x=extracted_coordinates.text\n",
        "    # print(\"Coordinates as Text\", x)\n",
        "\n",
        "    ##split coordinates by space\n",
        "    splitted_coordinates = x.split()\n",
        "    # print(\"Split coordinates by space\", splitted_coordinates)\n",
        "\n",
        "    ##create nested list\n",
        "    newlist=[]\n",
        "    for word in splitted_coordinates:\n",
        "        word = word.split(\",\")\n",
        "        newlist.append(word)\n",
        "    # print(\"Nested list\", newlist)\n",
        "\n",
        "    ##convert string to int\n",
        "    final_coordinates = convert_rec(newlist)\n",
        "    # print(final_coordinates)\n",
        "\n",
        "    ##create geometry\n",
        "    Geometry1 = Geometry(geometry={\"type\":\"Polygon\",\"coordinates\":[final_coordinates]}, crs=CRS.WGS84)\n",
        "\n",
        "    ##specify time slots\n",
        "    slots = wheat_time_interval(2021, 11, 1, 2022, 5, 15, 10) #start_year, start_month, start_date, end_year, end_month, end_date, chunks\n",
        "    results = [slot[1] for slot in slots]\n",
        "    print(results)\n",
        "\n",
        "    #specify path for saving data in drive\n",
        "    path = '/content/gdrive/MyDrive/Crop Mapping Data for Marking Wheat Region/'\n",
        "\n",
        "\n",
        "    ##get and save data\n",
        "    for slot in slots:\n",
        "        data = get_true_color_request(slot, file, Geometry1, path)\n",
        "        data.save_data()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_k2skNreFCS"
      },
      "source": [
        "#Request data for Multiple Polygons in single image using .kml file"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new dataframe for storing the polygons\n",
        "ground_truth = gpd.GeoDataFrame()\n",
        "driver = 'KML'\n",
        "\n",
        "#path to your .kml file\n",
        "polygon_file_path = \"/content/13.kml\"\n",
        "#extract filename from directory\n",
        "directory, file = os.path.split(polygon_file_path)\n",
        "\n",
        "# polpulate the dataframe using the .kml file containing all polygons\n",
        "for layer in fiona.listlayers(polygon_file_path):\n",
        "  s = gpd.read_file(polygon_file_path, driver=driver, layer=layer)\n",
        "  # print(s.geometry)\n",
        "  ground_truth = pd.concat([ground_truth, s], ignore_index=True)\n",
        "  # print(ground_truth)\n",
        "\n",
        "##extract geometrical coordinates of all the polygons in the .kml file\n",
        "multi_polygon_coordinates=[]\n",
        "shapefile = []\n",
        "for geo_shape in ground_truth.geometry.values:\n",
        "  # print(geo_shape)\n",
        "  shapefile = geo_shape\n",
        "  # new.extend([geo_shape])\n",
        "  temp_polygon = list(map(list, (geo_shape.exterior.coords)))\n",
        "  # print(\"temp_polygon\", temp_polygon)\n",
        "  multi_polygon_coordinates.append(list([temp_polygon]))\n",
        "\n",
        "# ##create geometry\n",
        "Geometry1 = Geometry(geometry={\"type\":\"MultiPolygon\",\"coordinates\": multi_polygon_coordinates}, crs=CRS.WGS84)\n",
        "# print(Geometry1)\n",
        "\n",
        "##specify time slots\n",
        "slots = wheat_time_interval(2021, 11, 1, 2022, 5, 15, 2) #start_year, start_month, start_date, end_year, end_month, end_date, chunks\n",
        "results = [slot[1] for slot in slots]\n",
        "print(results)\n",
        "\n",
        "#specify path for saving data in drive\n",
        "path = '/content/13'\n",
        "\n",
        "##get and save data\n",
        "for slot in slots:\n",
        "  data = get_true_color_request(slot, file, Geometry1, path)\n",
        "  data.save_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htzlEaTmAg67",
        "outputId": "a2540b0f-433b-4337-eaa4-2219a24a11b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Monthly time windows:\n",
            "\n",
            "('2021-11-01', '2022-02-06')\n",
            "['2022-02-06']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_Zo1UW2wGm4",
        "outputId": "0a67e639-9440-4fec-f893-432930556525"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Name Description                                           geometry\n",
            "0  00023              POLYGON Z ((72.56754 32.30949 0.00000, 72.5688...\n",
            "    Name Description                                           geometry\n",
            "0  00023              POLYGON Z ((72.56754 32.30949 0.00000, 72.5688...\n",
            "1  00024              POLYGON Z ((72.56781 32.31440 0.00000, 72.5677...\n",
            "    Name Description                                           geometry\n",
            "0  00023              POLYGON Z ((72.56754 32.30949 0.00000, 72.5688...\n",
            "1  00024              POLYGON Z ((72.56781 32.31440 0.00000, 72.5677...\n",
            "2  00025              POLYGON Z ((72.56781 32.31381 0.00000, 72.5676...\n",
            "    Name Description                                           geometry\n",
            "0  00023              POLYGON Z ((72.56754 32.30949 0.00000, 72.5688...\n",
            "1  00024              POLYGON Z ((72.56781 32.31440 0.00000, 72.5677...\n",
            "2  00025              POLYGON Z ((72.56781 32.31381 0.00000, 72.5676...\n",
            "3  00027              POLYGON Z ((72.57003 32.31592 0.00000, 72.5700...\n",
            "    Name Description                                           geometry\n",
            "0  00023              POLYGON Z ((72.56754 32.30949 0.00000, 72.5688...\n",
            "1  00024              POLYGON Z ((72.56781 32.31440 0.00000, 72.5677...\n",
            "2  00025              POLYGON Z ((72.56781 32.31381 0.00000, 72.5676...\n",
            "3  00027              POLYGON Z ((72.57003 32.31592 0.00000, 72.5700...\n",
            "4  00028              POLYGON Z ((72.56928 32.31487 0.00000, 72.5692...\n",
            "    Name Description                                           geometry\n",
            "0  00023              POLYGON Z ((72.56754 32.30949 0.00000, 72.5688...\n",
            "1  00024              POLYGON Z ((72.56781 32.31440 0.00000, 72.5677...\n",
            "2  00025              POLYGON Z ((72.56781 32.31381 0.00000, 72.5676...\n",
            "3  00027              POLYGON Z ((72.57003 32.31592 0.00000, 72.5700...\n",
            "4  00028              POLYGON Z ((72.56928 32.31487 0.00000, 72.5692...\n",
            "5  00030              POLYGON Z ((72.56906 32.31169 0.00000, 72.5701...\n",
            "    Name Description                                           geometry\n",
            "0  00023              POLYGON Z ((72.56754 32.30949 0.00000, 72.5688...\n",
            "1  00024              POLYGON Z ((72.56781 32.31440 0.00000, 72.5677...\n",
            "2  00025              POLYGON Z ((72.56781 32.31381 0.00000, 72.5676...\n",
            "3  00027              POLYGON Z ((72.57003 32.31592 0.00000, 72.5700...\n",
            "4  00028              POLYGON Z ((72.56928 32.31487 0.00000, 72.5692...\n",
            "5  00030              POLYGON Z ((72.56906 32.31169 0.00000, 72.5701...\n",
            "6  00031              POLYGON Z ((72.57070 32.31482 0.00000, 72.5705...\n",
            "    Name Description                                           geometry\n",
            "0  00023              POLYGON Z ((72.56754 32.30949 0.00000, 72.5688...\n",
            "1  00024              POLYGON Z ((72.56781 32.31440 0.00000, 72.5677...\n",
            "2  00025              POLYGON Z ((72.56781 32.31381 0.00000, 72.5676...\n",
            "3  00027              POLYGON Z ((72.57003 32.31592 0.00000, 72.5700...\n",
            "4  00028              POLYGON Z ((72.56928 32.31487 0.00000, 72.5692...\n",
            "5  00030              POLYGON Z ((72.56906 32.31169 0.00000, 72.5701...\n",
            "6  00031              POLYGON Z ((72.57070 32.31482 0.00000, 72.5705...\n",
            "7  00038              POLYGON Z ((72.56783 32.31547 0.00000, 72.5678...\n",
            "    Name Description                                           geometry\n",
            "0  00023              POLYGON Z ((72.56754 32.30949 0.00000, 72.5688...\n",
            "1  00024              POLYGON Z ((72.56781 32.31440 0.00000, 72.5677...\n",
            "2  00025              POLYGON Z ((72.56781 32.31381 0.00000, 72.5676...\n",
            "3  00027              POLYGON Z ((72.57003 32.31592 0.00000, 72.5700...\n",
            "4  00028              POLYGON Z ((72.56928 32.31487 0.00000, 72.5692...\n",
            "5  00030              POLYGON Z ((72.56906 32.31169 0.00000, 72.5701...\n",
            "6  00031              POLYGON Z ((72.57070 32.31482 0.00000, 72.5705...\n",
            "7  00038              POLYGON Z ((72.56783 32.31547 0.00000, 72.5678...\n",
            "8  00040              POLYGON Z ((72.56756 32.31164 0.00000, 72.5640...\n",
            "    Name Description                                           geometry\n",
            "0  00023              POLYGON Z ((72.56754 32.30949 0.00000, 72.5688...\n",
            "1  00024              POLYGON Z ((72.56781 32.31440 0.00000, 72.5677...\n",
            "2  00025              POLYGON Z ((72.56781 32.31381 0.00000, 72.5676...\n",
            "3  00027              POLYGON Z ((72.57003 32.31592 0.00000, 72.5700...\n",
            "4  00028              POLYGON Z ((72.56928 32.31487 0.00000, 72.5692...\n",
            "5  00030              POLYGON Z ((72.56906 32.31169 0.00000, 72.5701...\n",
            "6  00031              POLYGON Z ((72.57070 32.31482 0.00000, 72.5705...\n",
            "7  00038              POLYGON Z ((72.56783 32.31547 0.00000, 72.5678...\n",
            "8  00040              POLYGON Z ((72.56756 32.31164 0.00000, 72.5640...\n",
            "9  00042              POLYGON Z ((72.56497 32.31449 0.00000, 72.5656...\n",
            "     Name Description                                           geometry\n",
            "0   00023              POLYGON Z ((72.56754 32.30949 0.00000, 72.5688...\n",
            "1   00024              POLYGON Z ((72.56781 32.31440 0.00000, 72.5677...\n",
            "2   00025              POLYGON Z ((72.56781 32.31381 0.00000, 72.5676...\n",
            "3   00027              POLYGON Z ((72.57003 32.31592 0.00000, 72.5700...\n",
            "4   00028              POLYGON Z ((72.56928 32.31487 0.00000, 72.5692...\n",
            "5   00030              POLYGON Z ((72.56906 32.31169 0.00000, 72.5701...\n",
            "6   00031              POLYGON Z ((72.57070 32.31482 0.00000, 72.5705...\n",
            "7   00038              POLYGON Z ((72.56783 32.31547 0.00000, 72.5678...\n",
            "8   00040              POLYGON Z ((72.56756 32.31164 0.00000, 72.5640...\n",
            "9   00042              POLYGON Z ((72.56497 32.31449 0.00000, 72.5656...\n",
            "10  00044              POLYGON Z ((72.56792 32.31599 0.00000, 72.5678...\n",
            "[[[[72.5675370671109, 32.30949434468009, 0.0], [72.56886131312785, 32.30938152125135, 0.0], [72.5688677645843, 32.31018367273177, 0.0], [72.56759652281517, 32.31029653537397, 0.0], [72.5675370671109, 32.30949434468009, 0.0]]], [[[72.56780637543302, 32.31440218707565, 0.0], [72.56777554536697, 32.31386529864109, 0.0], [72.56910462267078, 32.31379052389631, 0.0], [72.56912961485818, 32.31433416604282, 0.0], [72.56780637543302, 32.31440218707565, 0.0]]], [[[72.56780659927315, 32.31380816867018, 0.0], [72.56767645186972, 32.31175589365817, 0.0], [72.56897032357134, 32.31172793179383, 0.0], [72.56907404728285, 32.31373748296122, 0.0], [72.56780659927315, 32.31380816867018, 0.0]]], [[[72.57003037472208, 32.31591758387662, 0.0], [72.57000051947117, 32.31487683284841, 0.0], [72.57062335434121, 32.31487890735438, 0.0], [72.57068191443234, 32.3158902846105, 0.0], [72.57003037472208, 32.31591758387662, 0.0]]], [[[72.56928056427063, 32.31486697850908, 0.0], [72.56920599267899, 32.31386112408828, 0.0], [72.57058692436247, 32.31380277727584, 0.0], [72.57060704815169, 32.3148169661879, 0.0], [72.56928056427063, 32.31486697850908, 0.0]]], [[[72.56905880723222, 32.3116878174335, 0.0], [72.57012914039932, 32.31164092725689, 0.0], [72.57016841272886, 32.31192040616041, 0.0], [72.5705077709486, 32.31194358613541, 0.0], [72.57052179756752, 32.31265542837986, 0.0], [72.56913153960782, 32.31270587894502, 0.0], [72.56905880723222, 32.3116878174335, 0.0]]], [[[72.57069527317758, 32.31481844488238, 0.0], [72.5705294409158, 32.31162475248038, 0.0], [72.57173238590777, 32.31155745532534, 0.0], [72.57196722116414, 32.31240311542005, 0.0], [72.57241418006386, 32.31363893032546, 0.0], [72.57248027851551, 32.31470125135334, 0.0], [72.57069527317758, 32.31481844488238, 0.0]]], [[[72.56782594195515, 32.31546670187035, 0.0], [72.56784956143105, 32.31604967196643, 0.0], [72.57069170933974, 32.315977120038, 0.0], [72.57091178537627, 32.32018578369267, 0.0], [72.56595524862784, 32.32038477280328, 0.0], [72.5657170515623, 32.31558792237094, 0.0], [72.56782594195515, 32.31546670187035, 0.0]]], [[[72.5675593607248, 32.31164396548007, 0.0], [72.56408590269082, 32.31180513858438, 0.0], [72.56389692361398, 32.30860288845577, 0.0], [72.56531458310229, 32.30845041133204, 0.0], [72.56532165524386, 32.30785128023427, 0.0], [72.56738197792568, 32.30843553250183, 0.0], [72.5675593607248, 32.31164396548007, 0.0]]], [[[72.56496642193643, 32.31448871220309, 0.0], [72.56569394708268, 32.31444207833011, 0.0], [72.56568767952565, 32.31385979648907, 0.0], [72.56490694499144, 32.31389258387507, 0.0], [72.56482495414947, 32.31289831044582, 0.0], [72.56563660948727, 32.31285952406757, 0.0], [72.56757558168783, 32.31275387095722, 0.0], [72.56772037509873, 32.31495342414316, 0.0], [72.56500959309119, 32.31502801236442, 0.0], [72.56496642193643, 32.31448871220309, 0.0]]], [[[72.56792432436397, 32.31599197993454, 0.0], [72.56784014250361, 32.31445786126076, 0.0], [72.56914509436521, 32.31438645884043, 0.0], [72.56922671373574, 32.3159310892773, 0.0], [72.56792432436397, 32.31599197993454, 0.0]]]]\n",
            "Monthly time windows:\n",
            "\n",
            "('2021-11-01', '2022-02-06')\n",
            "['2022-02-06']\n"
          ]
        }
      ],
      "source": [
        "# Create a new dataframe for storing the polygons\n",
        "ground_truth = gpd.GeoDataFrame()\n",
        "driver = 'KML'\n",
        "\n",
        "#path to your .kml file\n",
        "polygon_file_path = \"/content/Area 2 mask.kml\"\n",
        "#extract filename from directory\n",
        "directory, file = os.path.split(polygon_file_path)\n",
        "\n",
        "# polpulate the dataframe using the .kml file containing all polygons\n",
        "for layer in fiona.listlayers(polygon_file_path):\n",
        "  s = gpd.read_file(polygon_file_path, driver=driver, layer=layer)\n",
        "  ground_truth = pd.concat([ground_truth, s], ignore_index=True)\n",
        "  print(ground_truth)\n",
        "\n",
        "##extract geometrical coordinates of all the polygons in the .kml file\n",
        "multi_polygon_coordinates=[]\n",
        "for geo_shape in ground_truth.geometry.values:\n",
        "  # print(geo_shape)\n",
        "  # new.extend([geo_shape])\n",
        "  temp_polygon = list(map(list, (geo_shape.exterior.coords)))\n",
        "  # print(\"temp_polygon\", temp_polygon)\n",
        "  multi_polygon_coordinates.append(list([temp_polygon]))\n",
        "print(multi_polygon_coordinates)\n",
        "\n",
        "##create geometry\n",
        "Geometry1 = Geometry(geometry={\"type\":\"MultiPolygon\",\"coordinates\": multi_polygon_coordinates}, crs=CRS.WGS84)\n",
        "\n",
        "##specify time slots\n",
        "slots = wheat_time_interval(2021, 11, 1, 2022, 5, 15, 2) #start_year, start_month, start_date, end_year, end_month, end_date, chunks\n",
        "results = [slot[1] for slot in slots]\n",
        "print(results)\n",
        "\n",
        "#specify path for saving data in drive\n",
        "path = '/content/gdrive/MyDrive/Crop Mapping/Sargodha Wheat 2022/'\n",
        "\n",
        "##get and save data\n",
        "for slot in slots:\n",
        "  data = get_true_color_request(slot, file, Geometry1, path)\n",
        "  data.save_data()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnYI-UST2KIj"
      },
      "source": [
        "#Rename files with time from .json file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzbKIoPrTmV0",
        "outputId": "ffbbd8df-86bd-48fd-de77-52ffbfd18923"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1unUQ7z-Iyf"
      },
      "outputs": [],
      "source": [
        "\n",
        "#test->boundary->233h34h2jh232->response.tiff and request.json\n",
        "\n",
        "#dir0 = '/content/gdrive/MyDrive/Crop Mapping/GitHub/Landsat-Classification-Using-Neural-Network/Gujranwala_9sqkm/'\n",
        "# dir0 = '/content/gdrive/MyDrive/Crop Mapping/GitHub/Landsat-Classification-Using-Neural-Network/Gujranwala_9sqkm/Gujranwala_predict_builtup_1sqkm/'\n",
        "# dir0 = '/content/gdrive/MyDrive/Phenology/may/'\n",
        "dir0 = '/content/gdrive/MyDrive/Crop_Mapping/Final_Data/Sargodha_2021_1nov/'\n",
        "for main_file in (os.listdir(dir0)):\n",
        "  if main_file == \"Sargodha.kml\":\n",
        "  # # #mainfile = boundary or 000000\n",
        "  # # dir3 = '/content/gdrive/MyDrive/Phenology/2020-74/pol_20_7.kmz'\n",
        "    dir3 = os.path.join(dir0, main_file)\n",
        "\n",
        "    for fn in (os.listdir(dir3)):\n",
        "      ##fn = timestamps i.e. 000000 22-10-22\n",
        "      dir4 = os.path.join(dir3, dir3 + \"/\" + fn)\n",
        "      json_file_name = \"\"\n",
        "      tiff_file_name = \"\"\n",
        "      for filename in os.listdir(dir4):\n",
        "        ##filename = 22-10-22.tiff or json\n",
        "        if os.path.join(dir4, filename).endswith(\".json\"):\n",
        "          f = open(os.path.join(dir4, filename))\n",
        "          data = json.load(f)\n",
        "          for i in data:\n",
        "            date= data['payload']['input']['data'][0]['dataFilter']['timeRange']['to']\n",
        "            match = re.search(r'\\d{4}-\\d{2}-\\d{2}', date)\n",
        "            date = datetime.datetime.strptime(match.group(), '%Y-%m-%d').date()\n",
        "            date = date.strftime('%Y-%m-%d')\n",
        "            date_tiff = date +str(\".tiff\")\n",
        "            date_json = date +str(\".json\")\n",
        "            json_file_name = os.path.join(dir4, filename)\n",
        "        elif os.path.join(dir4, filename).endswith(\".tiff\"):\n",
        "          tiff_file_name = os.path.join(dir4, filename)\n",
        "        if len(json_file_name) != 0 and len(tiff_file_name) != 0:\n",
        "          os.rename(json_file_name, os.path.join(dir4, date_json))\n",
        "          os.rename(tiff_file_name, os.path.join(dir4, date_tiff))\n",
        "\n",
        "    os.rename(os.path.join(dir3,fn), os.path.join(dir3, date))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uyOrBVPX4VZ"
      },
      "source": [
        "#Seperate .tiff and .json files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkAa3gOL6JXu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "source_folder = r\"/content/gdrive/MyDrive/Crop_Mapping/Final_Data/Sargodha_2021_1nov/\"\n",
        "destination_folder_json = \"/content/gdrive/MyDrive/Crop_Mapping/Final_Data/Sargodha_2021_1nov/Data.json/\"\n",
        "destination_folder_tiff = \"/content/gdrive/MyDrive/Crop_Mapping/Final_Data/Sargodha_2021_1nov/Data.tiff/\"\n",
        "\n",
        "for main_file in (os.listdir(source_folder)):\n",
        "  ##mainfile = boundary or 000000\n",
        "    # print(main_file)\n",
        "  # if (main_file) == \"s2 data 30km2 updated.kml\":\n",
        "  dir3 = os.path.join(source_folder, main_file)\n",
        "\n",
        "  for fn in (os.listdir(dir3)):\n",
        "    ##fn = boundary/timestamps i.e. 000000 22-10-22\n",
        "    dir4 = os.path.join(dir3, dir3 + \"/\" + fn)\n",
        "    json_file_name = \"\"\n",
        "    tiff_file_name = \"\"\n",
        "    for filename in os.listdir(dir4):\n",
        "      ##filename = boundary/timestamps/22-10-22.tiff or json\n",
        "      if os.path.join(dir4, filename).endswith(\".json\"):\n",
        "        json_file_name = os.path.join(dir4, filename)\n",
        "\n",
        "      elif os.path.join(dir4, filename).endswith(\".tiff\"):\n",
        "        tiff_file_name = os.path.join(dir4, filename)\n",
        "\n",
        "      if len(json_file_name) != 0 and len(tiff_file_name) != 0:\n",
        "        isExist_destination_folder_json = os.path.exists(destination_folder_json)\n",
        "        isExist_destination_folder_tiff = os.path.exists(destination_folder_tiff)\n",
        "        if not isExist_destination_folder_json:\n",
        "          # Create a new directory because it does not exist\n",
        "          os.makedirs(destination_folder_json)\n",
        "        if not isExist_destination_folder_tiff:\n",
        "          # Create a new directory because it does not exist\n",
        "          os.makedirs(destination_folder_tiff)\n",
        "\n",
        "        shutil.move(json_file_name, destination_folder_json)\n",
        "        shutil.move(tiff_file_name, destination_folder_tiff)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f26sSqxGpIoh"
      },
      "source": [
        "#Cloud Removal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fScoq1tDGAb0",
        "outputId": "d0b408e8-d4df-4ada-9b8f-608e799a203e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sargodha.kml\n",
            "Data.json\n",
            "Data.tiff\n",
            "Data.tiff\n",
            "(298, 212)\n",
            "True\n",
            "0\n",
            "(298, 212)\n",
            "False\n",
            "(298, 212)\n",
            "False\n",
            "(298, 212)\n",
            "False\n",
            "(298, 212)\n",
            "False\n",
            "(298, 212)\n",
            "False\n",
            "(298, 212)\n",
            "False\n",
            "(298, 212)\n",
            "False\n",
            "(298, 212)\n",
            "False\n",
            "(298, 212)\n",
            "False\n",
            "(298, 212)\n",
            "False\n",
            "(298, 212)\n",
            "True\n",
            "11\n",
            "(298, 212)\n",
            "True\n",
            "12\n",
            "(298, 212)\n",
            "True\n",
            "13\n",
            "(298, 212)\n",
            "True\n",
            "14\n",
            "(298, 212)\n",
            "True\n",
            "15\n",
            "(298, 212)\n",
            "True\n",
            "16\n",
            "(298, 212)\n",
            "True\n",
            "17\n",
            "(298, 212)\n",
            "True\n",
            "18\n",
            "(298, 212)\n",
            "False\n",
            "(298, 212)\n",
            "True\n",
            "20\n",
            "(298, 212)\n",
            "False\n",
            "(298, 212)\n",
            "True\n",
            "22\n",
            "(298, 212)\n",
            "True\n",
            "23\n",
            "(298, 212)\n",
            "True\n",
            "24\n",
            "(298, 212)\n",
            "True\n",
            "25\n",
            "(298, 212)\n",
            "False\n",
            "(298, 212)\n",
            "False\n",
            "(298, 212)\n",
            "False\n",
            "(298, 212)\n",
            "False\n",
            "(298, 212)\n",
            "False\n",
            "(298, 212)\n",
            "False\n",
            "Images removed 14\n"
          ]
        }
      ],
      "source": [
        "def cloud_removal(i):\n",
        "\n",
        "  #enumerate for the time-series of each patch (with all its bands)\n",
        "  for ids, folder in enumerate(data_folders):\n",
        "\n",
        "    # print(ids)                                                                  ##ids=0,1,2....\n",
        "    print(folder)                                                               ##folder=  Data.json', 'Data.tiff', 'Mask'\n",
        "\n",
        "    if (folder == \"Data.tiff\"):\n",
        "      print(folder)\n",
        "      n=0\n",
        "      s2_data_path = os.path.join(data_path, folder)                            #/content/gdrive/MyDrive/Crop Mapping/Sentinel Hub Dataset for Code/1 S2_10m_all bands upsampled_5.5months_bboxtodimensions/Data.tiff\n",
        "      # print(s2_data_path)\n",
        "      s2_data = next(os.walk(s2_data_path))[2]\n",
        "      # print(s2_data)                                                            #['2021-11-20.tiff', '2021-11-26.tiff'....\n",
        "\n",
        "      for ids2, tiff_file in enumerate(s2_data):\n",
        "        img = gdal.Open(os.path.join(s2_data_path, tiff_file) , gdal.GA_ReadOnly)                  #open each tiff file (with all its bands)\n",
        "        # print(img)# img = img.ReadAsArray()                                 #read each tiff file as array (with all its bands)\n",
        "        band = img.GetRasterBand(5)\n",
        "        x_img_arr = band.ReadAsArray()\n",
        "        print(x_img_arr.shape)                                 #read each tiff file as array (with all its bands)\n",
        "\n",
        "        all_zeros = np.any(x_img_arr == 0) #o means no data, if any value is 0 then True\n",
        "        print(all_zeros)\n",
        "        if(all_zeros==True):\n",
        "          if os.path.exists(os.path.join(s2_data_path, tiff_file)):\n",
        "            os.remove(os.path.join(s2_data_path, tiff_file))\n",
        "            n=n+1\n",
        "            print(ids2)\n",
        "      print(\"Images removed\", n)\n",
        "\n",
        "\n",
        "data_path = '/content/gdrive/MyDrive/Crop_Mapping/Final_Data/Sargodha_2021_1nov/'\n",
        "data_folders = next(os.walk(data_path))[1]\n",
        "# print(data_folders)                                                              ##data_folders=  Data.json', 'Data.tiff', 'Mask'\n",
        "i=1\n",
        "cloud_removal(i)                                                #create dataset with shape (time, height, width, bands)->(29, 79, 137, 12)\n",
        "\n",
        "#164 total for sargodha, removed 132, remaining 32"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}